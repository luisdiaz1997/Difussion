{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest Possible Diffusion - No Time Embedding!\n",
    "\n",
    "Let's strip it down to the absolute basics:\n",
    "- ✅ Simple Conv autoencoder (like VAE encoder/decoder)\n",
    "- ✅ NO time embedding - same network for all timesteps\n",
    "- ✅ Just learn: noisy image → predicted noise\n",
    "\n",
    "**Why this works:**\n",
    "The network can still implicitly learn different noise levels from the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from realistica import NoiseScheduler, TinyConvDenoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "config = {\n",
    "    'batch_size': 128,\n",
    "    'num_epochs': 20,\n",
    "    'lr': 1e-3,\n",
    "    'num_timesteps': 1000,\n",
    "}\n",
    "\n",
    "os.makedirs('outputs/mnist_conv_simple/samples', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"Dataset: {len(train_dataset)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model - Super Simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise scheduler\n",
    "noise_scheduler = NoiseScheduler(\n",
    "    num_timesteps=config['num_timesteps'],\n",
    "    beta_start=0.0001,\n",
    "    beta_end=0.02,\n",
    "    schedule_type='linear',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Tiny conv model - NO time embedding!\n",
    "model = TinyConvDenoiser().to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Parameters: {num_params:,}\")\n",
    "print(f\"\\nArchitecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Dead Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(config['num_epochs']):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']}\")\n",
    "    for images, _ in pbar:\n",
    "        images = images.to(device)\n",
    "        batch_size = images.shape[0]\n",
    "        \n",
    "        # Random timesteps\n",
    "        t = noise_scheduler.sample_timesteps(batch_size)\n",
    "        \n",
    "        # Add noise\n",
    "        noisy_images, noise = noise_scheduler.add_noise(images, t)\n",
    "        \n",
    "        # Predict noise (NO time input!)\n",
    "        pred_noise = model(noisy_images)\n",
    "        \n",
    "        # Loss\n",
    "        loss = criterion(pred_noise, noise)\n",
    "        \n",
    "        # Update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        losses.append(loss.item())\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} - Avg Loss: {epoch_loss/len(train_loader):.6f}\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(num_samples=64):\n",
    "    model.eval()\n",
    "    \n",
    "    # Start from noise\n",
    "    x = torch.randn(num_samples, 1, 28, 28, device=device)\n",
    "    \n",
    "    # Denoise\n",
    "    for t in tqdm(reversed(range(config['num_timesteps'])), desc='Sampling'):\n",
    "        t_batch = torch.tensor([t] * num_samples, device=device)\n",
    "        \n",
    "        # Predict noise (model ignores t)\n",
    "        pred_noise = model(x)\n",
    "        \n",
    "        alpha = noise_scheduler.alphas[t]\n",
    "        alpha_cumprod = noise_scheduler.alphas_cumprod[t]\n",
    "        beta = noise_scheduler.betas[t]\n",
    "        \n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        \n",
    "        # DDPM step\n",
    "        x = (1 / torch.sqrt(alpha)) * (x - (beta / torch.sqrt(1 - alpha_cumprod)) * pred_noise)\n",
    "        x = x + torch.sqrt(beta) * noise\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Generate\n",
    "samples = sample(64)\n",
    "\n",
    "# Show\n",
    "grid = make_grid(samples, nrow=8, normalize=True, value_range=(-1, 1))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Generated Digits (No Time Embedding!)')\n",
    "plt.savefig('outputs/mnist_conv_simple/samples/generated.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_steps(num_samples=8, steps_to_show=10):\n",
    "    model.eval()\n",
    "    x = torch.randn(num_samples, 1, 28, 28, device=device)\n",
    "    \n",
    "    timesteps = list(reversed(range(config['num_timesteps'])))\n",
    "    interval = len(timesteps) // steps_to_show\n",
    "    saved = []\n",
    "    \n",
    "    for i, t in enumerate(tqdm(timesteps)):\n",
    "        if i % interval == 0 or i == len(timesteps) - 1:\n",
    "            saved.append(x.cpu().clone())\n",
    "        \n",
    "        pred_noise = model(x)\n",
    "        \n",
    "        alpha = noise_scheduler.alphas[t]\n",
    "        alpha_cumprod = noise_scheduler.alphas_cumprod[t]\n",
    "        beta = noise_scheduler.betas[t]\n",
    "        noise = torch.randn_like(x) if t > 0 else torch.zeros_like(x)\n",
    "        \n",
    "        x = (1 / torch.sqrt(alpha)) * (x - (beta / torch.sqrt(1 - alpha_cumprod)) * pred_noise)\n",
    "        x = x + torch.sqrt(beta) * noise\n",
    "    \n",
    "    return saved\n",
    "\n",
    "steps = sample_steps(8, 10)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(8, len(steps), figsize=(15, 10))\n",
    "for i in range(8):\n",
    "    for j, imgs in enumerate(steps):\n",
    "        axes[i, j].imshow(imgs[i, 0].numpy(), cmap='gray', vmin=-1, vmax=1)\n",
    "        axes[i, j].axis('off')\n",
    "        if i == 0:\n",
    "            axes[i, j].set_title(f'{j}')\n",
    "\n",
    "plt.suptitle('Denoising Process (No Time Embedding)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does it work?\n",
    "\n",
    "**Expected:**\n",
    "- Model has only ~50K parameters\n",
    "- No time conditioning at all\n",
    "- Should still produce digit-like shapes\n",
    "- Quality won't be amazing, but proves the concept\n",
    "\n",
    "**If you see digits:** ✅ Your diffusion setup works!\n",
    "\n",
    "**If you see maze patterns:** Try:\n",
    "1. More epochs (30-50)\n",
    "2. Lower learning rate (1e-4)\n",
    "3. Check data normalization is [-1, 1]\n",
    "\n",
    "**Next step:** Add time embedding for better quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
